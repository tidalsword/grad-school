{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Tensorflow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.imgur.com/l8xexM0.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import display, HTML\n",
    "Image(url= \"https://i.imgur.com/l8xexM0.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow is a flexible, open-source interface for expressing machine learning algorithms. TensorFlow was developed by Google as a more efficient way to create and use deep learning for research and development.  It is a library that was built with neural networking in mind, making it a great tool for deep learning.  TensorFlow is a scalable software library, working on a laptop and in massive production environments.  TensorFlow has several APIs that allow it to work with Python, R, C++, and others.  It is also highly configurable, able to run on multiple CPUs and GPUs.  TensorFlow also comes with a logging interface called “Tensorboard,” which allows the user to examine the model in a web interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More on the history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.imgur.com/KvZ88ZP.jpg\" width=\"300\" height=\"225\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://i.imgur.com/KvZ88ZP.jpg\", width=300, height=225)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow was initially developed by the Google Brain team for use on internal projects. Tensorflow is actually the second generation of DistBelief, a proprietary ML system based on deep learning neural nets that was created in 2011. Distbelief was used for research and application like speech recognition. Tensorflow was released as a more robust version on a Apache 2.0 open source license in 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it work?\n",
    "\n",
    "To understand Tensorflow, we need to understand “tensors.”  Tensors can be described as a multidimensional array (n-dimensional structures).  Tensors represent whatever we define them as, such as the pixels of an image, and can be altered as it “flows” between operations, which is where we get the name “TensorFlow.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.imgur.com/nSrJKcp.png?1\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://i.imgur.com/nSrJKcp.png?1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can we use it for?\n",
    "\n",
    "Tensorflow is mainly used for neural networks and is a very powerful tool for image recognition and audio recognition.  In the example below, we will walk through how to build a neural network in Tensorflow that can identify handwritten numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.imgur.com/7pvfFHC.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://i.imgur.com/7pvfFHC.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Neural Net in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In building this neural network, we are going to use a package called \"Keras.\"  This will allow for more complex deep learning in less code while maintaining an easy to follow structure.  I'm also going to use a GPU rather than a CPU in this model as an example. Using a GPU is much faster than processing with a CPU for this type of analysis. More information on how to set this up can be found in the TensorFlow documentation: https://www.tensorflow.org/install/install_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supressing warnings to save space\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#This verifies that the GPU is recognized and used by Tensorflow\n",
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we are going to be working with is called \"MNIST\", a dataset of handwritten numerical digits.  The images are 28 x 28 pixels, and are in grayscale, meaning there is one channel.  Shown below are some samples of these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.imgur.com/uWjw86G.png\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://i.imgur.com/uWjw86G.png\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of this model is predict and identify each digit correctly. The Neural Net that is going to be created is called a convolutional neural network (CNN), which consists of a convolutional layer, a pooling layer, and a fully connected layer.  CNNs are useful in image recognition because they allow for deep learning without needing a high number of neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by loading in the packages.  As you can see, we are loading in TensorFlow, Keras, as well as numpy and sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input object which reads data from MNIST datasets.  Perform one-hot encoding to define the digit\n",
    "def load_data(img_dir):\n",
    "    return np.array([cv2.imread(os.path.join(img_dir, img)).flatten() for img in os.listdir(img_dir) if img.endswith(\".jpg\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will load in the dataset as \"mnist\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-40fced941258>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting D:/Google Drive/Corey - School/!Spring 2018 B/BIA 6303 - Predictive Models/HW_Final_Project/data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting D:/Google Drive/Corey - School/!Spring 2018 B/BIA 6303 - Predictive Models/HW_Final_Project/data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting D:/Google Drive/Corey - School/!Spring 2018 B/BIA 6303 - Predictive Models/HW_Final_Project/data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting D:/Google Drive/Corey - School/!Spring 2018 B/BIA 6303 - Predictive Models/HW_Final_Project/data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"D:/Google Drive/Corey - School/!Spring 2018 B/BIA 6303 - Predictive Models/HW_Final_Project/data/MNIST_data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start the session here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the size of the image this way prevents any accidents in coding the model down the road.  Since we know the the image is 28 by 28, both the row and column will be 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rows = 28\n",
    "image_cols = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we start defining the shape to the image tensor.  The 28 is the height and weight, which adding the 1 implies the number of color channels.  Since we are only using grayscale, this is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the training and test images to 28 X 28 X 1 \n",
    "train_images = mnist.train.images.reshape(mnist.train.images.shape[0],image_rows, image_cols, 1)\n",
    "test_images =  mnist.test.images.reshape(mnist.test.images.shape[0], image_rows, image_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the images, just to make sure they are showing up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADt9JREFUeJzt3X+MVfWZx/HPowUxlEQJcUAKS7cQqZEIdcBNqIubZoBdiUgMBP4RXVKaWBJJNrrGH6lEUbLaKtGkCQQsGAs0iEiaRqhmXVE3ykAQLdiWNLSdhTAomkIUq/jsH3OmmcKc75m5v85lnvcrMXPvfe455/Eynzn33O8952vuLgDxXFR2AwDKQfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwT1tUZuzMz4OiFQZ+5ufXleVXt+M5ttZr81s8Nmdm816wLQWFbpd/vN7GJJv5PUJqlD0h5Ji9z9YGIZ9vxAnTVizz9N0mF3/4O7/1XSZklzq1gfgAaqJvyjJf25x/2O7LG/Y2ZLzazdzNqr2BaAGqvmA7/e3lqc97be3ddIWiPxth9oJtXs+Tskjelx/xuSjlbXDoBGqSb8eyRNMLNvmtlgSQsl7ahNWwDqreK3/e7+pZktk7RT0sWS1rv7b2rWGYC6qnior6KNccwP1F1DvuQD4MJF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFAVT9EtSWZ2RNIpSWclfenurbVoCgPH9u3bc2s333xzVetesmRJsr558+bc2meffVbVtgeCqsKf+Rd3/7AG6wHQQLztB4KqNvwuaZeZ7TWzpbVoCEBjVPu2f7q7HzWzKyT92sw+cPfXez4h+6PAHwagyVS153f3o9nPTkkvSprWy3PWuHsrHwYCzaXi8JvZUDMb1n1b0kxJ79eqMQD1Vc3b/hZJL5pZ93p+7u4v16QrAHVn7t64jZk1bmNNZMiQIcn67Nmzk/VJkyYl64sWLep3T92eeuqpZH3jxo3J+pkzZ5L10aNH59beeeed5LIjR45M1rMdT659+/bl1lpbB+5RqLunX5gMQ31AUIQfCIrwA0ERfiAowg8ERfiBoBjq66NRo0bl1tra2pLL3nXXXcn6lClTkvVG/huda9euXcn6/Pnzk/XTp0/n1latWpVc9u67707Wi4b6Tpw4kVtraWlJLnshY6gPQBLhB4Ii/EBQhB8IivADQRF+ICjCDwRVi6v3hjBt2nkXKfqbZ599toGdnK+joyO3tmXLluSyN910U7I+a9asZL1o/QsXLsytDR8+PLks6os9PxAU4QeCIvxAUIQfCIrwA0ERfiAowg8Exfn8mcsuuyxZf/PNN3NrEydOrGrbb7zxRrK+bdu2ZP25557LrZ08ebKinrqtXbs2WT948GCyPnPmzIpqfVF0Pv/999+fW3vssceq2nYz43x+AEmEHwiK8ANBEX4gKMIPBEX4gaAIPxBU4Ti/ma2XNEdSp7tfkz02XNIWSeMkHZG0wN0/LtxYE4/zjxgxIlnv7OyseN27d+9O1mfMmFHxusu2Y8eOZH3OnDl123bquxeSdMMNN9Rt282sluP8P5N07gTy90p61d0nSHo1uw/gAlIYfnd/XdK5XxObK2lDdnuDpFtq3BeAOqv0mL/F3Y9JUvbzitq1BKAR6n4NPzNbKmlpvbcDoH8q3fMfN7NRkpT9zP00zN3XuHuru7dWuC0AdVBp+HdIWpzdXizppdq0A6BRCsNvZpsk/a+kq8ysw8yWSFolqc3Mfi+pLbsP4AJSeMzv7otySt+rcS+lKvq+w+eff55bGzx4cHLZSZMmJeutrekjovb29mS9ngYNGpSsX3XVVcl6NdeLOHDgQLK+YsWKitcNvuEHhEX4gaAIPxAU4QeCIvxAUIQfCIopujMfffRRsp467faZZ55JLnvdddcl6y+//HKyXnRKcMptt92WrBdNk/3ggw8m6+PHj+93T91OnTqVrK9bty5Zf+WVVyreNtjzA2ERfiAowg8ERfiBoAg/EBThB4Ii/EBQTNFdA7NmzUrWi6aDnjx5crJezb9R0RTdRacjDxs2LFmvprfly5cn608//XTF646MKboBJBF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM8zdAS0tLsn777bcn6/PmzUvWp06d2t+W+swsPWRc9PuTuhZBW1tbctkvvvgiWUfvGOcHkET4gaAIPxAU4QeCIvxAUIQfCIrwA0EVjvOb2XpJcyR1uvs12WMPSfq+pBPZ0+5z918VbizoOH+9pa4H8NZbbyWXHTJkSLJe7Th/StF19++8885k/fDhwxVveyCr5Tj/zyTN7uXxJ919cvZfYfABNJfC8Lv765LSl4MBcMGp5ph/mZkdMLP1ZnZ5zToC0BCVhv+nkr4labKkY5J+nPdEM1tqZu1m1l7htgDUQUXhd/fj7n7W3b+StFbStMRz17h7q7u3VtokgNqrKPxmNqrH3XmS3q9NOwAapXCKbjPbJOlGSSPMrEPSjyTdaGaTJbmkI5J+UMceAdQB5/MPAAsWLMitbdq0qap1F43zF80LMHTo0Nxa0ZwBe/bsSdaLruv//PPPJ+sDFefzA0gi/EBQhB8IivADQRF+ICjCDwTFUN8F4JJLLknWX3vttdzatGm5X77skw8++CBZv/7665P12bN7OyG0y8qVK5PLjh8/Pln/+OOPk/XVq1fn1h5++OHkshcyhvoAJBF+ICjCDwRF+IGgCD8QFOEHgiL8QFCF5/OjfIMGDUrWR44cWbdt79y5M1k/ffp0sr5169bcWtFlxZ988slkff78+cn6Pffck6ynPP7448n6mTNnKl53s2DPDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBcT7/BWDx4sXJ+vr16+u27SuvvDJZP378eN22fccddyTr69atS9ZTv9v79+9PLjt9+vRkvZnH+TmfH0AS4QeCIvxAUIQfCIrwA0ERfiAowg8EVXg+v5mNkbRR0khJX0la4+6rzWy4pC2Sxkk6ImmBu6cvpI6KFE2TXVSvRj3H8a+99tpk/dFHH03Wq/n/Hjt2bLJeNFdCM4/z91Vf9vxfSvoPd/+2pH+S9EMzu1rSvZJedfcJkl7N7gO4QBSG392Pufu+7PYpSYckjZY0V9KG7GkbJN1SryYB1F6/jvnNbJykKZLeltTi7sekrj8Qkq6odXMA6qfP1/Azs69LekHScnf/S1+Pt8xsqaSllbUHoF76tOc3s0HqCv7z7r4te/i4mY3K6qMkdfa2rLuvcfdWd2+tRcMAaqMw/Na1i18n6ZC7/6RHaYek7tPNFkt6qfbtAaiXwlN6zey7knZLek9dQ32SdJ+6jvt/IWmspD9Jmu/uJwvWxSm9FRg6dGiyvm/fvtxa0TTX1W77oovS+4+JEyfm1p544onksjNmzEjWiw49z549m1tbsWJFctlHHnkkWW9mfT2lt/CY393fkJS3su/1pykAzYNv+AFBEX4gKMIPBEX4gaAIPxAU4QeC4tLdA8Dq1atza8uWLatq3e+++26yXjR9+NVXX13V9lOKxvn37t2bW5s6dWqt22kaXLobQBLhB4Ii/EBQhB8IivADQRF+ICjCDwTFOP8AMHjw4Nzahg0bcmuStGDBgmS9aCy9kb8/59q6dWuynpri+9NPP611O02DcX4ASYQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/APcpZdemqw/8MADyfqtt96arE+YMKHfPXX75JNPkvUlS5Yk69u3b6942wMZ4/wAkgg/EBThB4Ii/EBQhB8IivADQRF+IKjCcX4zGyNpo6SRkr6StMbdV5vZQ5K+L+lE9tT73P1XBetinB+os76O8/cl/KMkjXL3fWY2TNJeSbdIWiDptLs/0demCD9Qf30N/9f6sKJjko5lt0+Z2SFJo6trD0DZ+nXMb2bjJE2R9Hb20DIzO2Bm683s8pxllppZu5m1V9UpgJrq83f7zezrkv5H0kp332ZmLZI+lOSSHlbXocG/F6yDt/1AndXsmF+SzGyQpF9K2unuP+mlPk7SL939moL1EH6gzmp2Yo91Xb51naRDPYOffRDYbZ6k9/vbJIDy9OXT/u9K2i3pPXUN9UnSfZIWSZqsrrf9RyT9IPtwMLUu9vxAndX0bX+tEH6g/jifH0AS4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+IKjCC3jW2IeS/tjj/ojssWbUrL01a18SvVWqlr39Q1+f2NDz+c/buFm7u7eW1kBCs/bWrH1J9FapsnrjbT8QFOEHgio7/GtK3n5Ks/bWrH1J9FapUnor9ZgfQHnK3vMDKEkp4Tez2Wb2WzM7bGb3ltFDHjM7Ymbvmdn+sqcYy6ZB6zSz93s8NtzMfm1mv89+9jpNWkm9PWRm/5e9dvvN7N9K6m2Mmf23mR0ys9+Y2V3Z46W+dom+SnndGv6238wulvQ7SW2SOiTtkbTI3Q82tJEcZnZEUqu7lz4mbGb/LOm0pI3dsyGZ2X9JOunuq7I/nJe7+382SW8PqZ8zN9ept7yZpW9Xia9dLWe8roUy9vzTJB129z+4+18lbZY0t4Q+mp67vy7p5DkPz5W0Ibu9QV2/PA2X01tTcPdj7r4vu31KUvfM0qW+dom+SlFG+EdL+nOP+x1qrim/XdIuM9trZkvLbqYXLd0zI2U/ryi5n3MVztzcSOfMLN00r10lM17XWhnh7202kWYacpju7t+R9K+Sfpi9vUXf/FTSt9Q1jdsxST8us5lsZukXJC1397+U2UtPvfRVyutWRvg7JI3pcf8bko6W0Eev3P1o9rNT0ovqOkxpJse7J0nNfnaW3M/fuPtxdz/r7l9JWqsSX7tsZukXJD3v7tuyh0t/7Xrrq6zXrYzw75E0wcy+aWaDJS2UtKOEPs5jZkOzD2JkZkMlzVTzzT68Q9Li7PZiSS+V2MvfaZaZm/NmllbJr12zzXhdypd8sqGMpyRdLGm9u69seBO9MLN/VNfeXuo64/HnZfZmZpsk3aius76OS/qRpO2SfiFprKQ/SZrv7g3/4C2ntxvVz5mb69Rb3szSb6vE166WM17XpB++4QfExDf8gKAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E9f/rF4+V3ngTBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ac5c0e78d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ac5c0e7978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gen_image(arr):\n",
    "    two_d = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)\n",
    "    plt.imshow(two_d, interpolation='nearest', cmap='gray')\n",
    "    return plt\n",
    "\n",
    "# Get a batch of two random images and show in a pop-up window.\n",
    "batch_xs, batch_ys = mnist.test.next_batch(2)\n",
    "gen_image(batch_xs[0]).show()\n",
    "gen_image(batch_xs[1]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the values for our layers.  Again, defining them like this prevents any confusing errors due to typos. This is also very handy when the layers tend to have the same specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer values\n",
    "num_filters = 32                # Number of conv filters\n",
    "max_pool_size = (2, 2)          # shape of MaxPool\n",
    "conv_kernel_size = (3, 3)       # conv kernel shape\n",
    "imag_shape = (28,28,1)          # the shape of the image as was described before\n",
    "num_classes = 10                # The number different possible predictions (0-9)\n",
    "drop_prob = 0.5                 # fraction to drop (0-1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start defining our model!  The Sequential model type is just like it sounds, it is a sequential list of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model type\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define each layer.  Here, we will have 2 convolutional layers, 2 pooling layers, and a fully connected layer.  The convolutional layer will divide each image up and measure the color scale, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.imgur.com/0z2N9q6.png\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://i.imgur.com/0z2N9q6.png\", width=400, height=400)\n",
    "#Credit to pluralsight for the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pooling layer reduces the size of the grid by keeping the average of the sections, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.imgur.com/Ko1Ydpe.png\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://i.imgur.com/Ko1Ydpe.png\", width=400, height=400)\n",
    "#Credit to pluralsight for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 1st convlution layer.  We use border_mode= and input_shape only on first layer\n",
    "# border_mode=value restricts convolution to only where the input and the filter fully overlap (ie. not partial overlap)\n",
    "model.add(Convolution2D(num_filters, conv_kernel_size[0], conv_kernel_size[1], border_mode='valid',\n",
    "                        input_shape=imag_shape))\n",
    "model.add(Activation('relu'))\n",
    "# take results and run through max_pool\n",
    "model.add(MaxPooling2D(pool_size=max_pool_size))\n",
    "\n",
    "# 2nd Convolution layer\n",
    "model.add(Convolution2D(num_filters, conv_kernel_size[0], conv_kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=max_pool_size))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))   # Fully connected layer in Keras\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use a clever trick to drop out some neurons to help reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout some neurons to reduce overfitting\n",
    "model.add(Dropout(drop_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readout layer\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compile the model and tell it how to optimize and calculate loss.  We also tell it what metrics we care about, which is accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set loss and measurement, optimizer, and metric used to evaluate loss\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we fit the model, we can add in some checkpoints to catch some logging that will display in tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, \n",
    "                         write_images=True, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit the model!  Here, we are fitting the model in batches of 128 images, and in 2 \"epochs\", meaning we going through the training data 2 times.  We are also setting it to verbose mode we we can see it work.  In order to test the model at the same time, 10,000 samples were held over to validate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "# fit the training data to the model.  Displays the time, loss, and validation accuracy on the test data\n",
    "model.fit(train_images, mnist.train.labels, batch_size=128, nb_epoch=2,\n",
    "          verbose=1, validation_data=(test_images, mnist.test.labels), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see how we did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual test labels: [7 2 1 ... 4 5 6]\n",
      "Predicted test labels: [7 2 1 ... 4 5 6]\n",
      "Accuracy score: 0.982\n"
     ]
    }
   ],
   "source": [
    "predicted_test_labels = np.argmax(model.predict(test_images), axis=1)\n",
    "test_labels = np.argmax(mnist.test.labels, axis=1)\n",
    "print (\"Actual test labels:\", test_labels)\n",
    "print (\"Predicted test labels:\", predicted_test_labels)\n",
    "print(\"Tensor Flow Accuracy Score\", accuracy_score(test_labels, predicted_test_labels))\n",
    "print(classification_report(test_labels, predicted_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Accuracy Score 0.982\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99       980\n",
      "          1       0.99      0.99      0.99      1135\n",
      "          2       0.98      0.99      0.99      1032\n",
      "          3       0.98      0.98      0.98      1010\n",
      "          4       0.99      0.98      0.99       982\n",
      "          5       0.96      0.99      0.97       892\n",
      "          6       1.00      0.96      0.98       958\n",
      "          7       0.99      0.97      0.98      1028\n",
      "          8       0.97      0.99      0.98       974\n",
      "          9       0.98      0.97      0.98      1009\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensor Flow Accuracy Score\", accuracy_score(test_labels, predicted_test_labels))\n",
    "print(classification_report(test_labels, predicted_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results, there is a chance that this is overfit. So, now would be the time to perform some k-fold cross validation. However, I won't be able to complete this due to the computational overhead that is required.  In Scikit Learn, k-folds cross validation is built in.  This is unfortunately not the case in TensorFlow.\n",
    "\n",
    "But before we go, lets take a look at TensorBoard!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
