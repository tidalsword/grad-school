---
title: "R Notebook"
output: html_notebook
---

For this assignment, you will complete following steps:

.	Examine the data structure
.	Demonstrate the descriptive information of the variables that you are interested in

.	Select only numeric variables to conduct cluster analysis
    o	Decide the number of clusters
    o	Try and compare different linkage options
    o	Try different cluster methods such as Hierarchical Clustering and Kmeans
    o	Decide the best cluster solution
    o	Show the differences of key factors' characteristics across clusters
    o	Check the differences of the 3 outcome variables across the clusters
    o	Discuss your findings and implications to understand employee profiles and satisfaction
    
.	Select numeric variables and categorical variables (mixed data) and use PAM() to conduct cluster analysis
    o	Decide the number of clusters
    o	Decide the best cluster solution
    o	Show the differences of key factors' characteristics across clusters 
    o	Check the differences of the 3 outcome variables across the clusters
    o	Discuss your findings and implications to understand employee profiles and satisfaction

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = normalizePath("C:/Users/ca034330/Google Drive/Corey - School/!Spring 2019 B/Assignment1/data/"))
#knitr::opts_knit$set(root.dir = normalizePath("D:/Google Drive/Corey - School/!Spring 2019 B/Assignment1/data/"))
```

```{r}
library(cluster) 
library(NbClust) 
library(factoextra)
```

```{r data_load}
w <- read_xlsx("Employee profile and satisfaction data.xlsx",col_names = TRUE)
```

```{r}
names(w)
summary(w)
str(w)
```

```{r}
w1<- as.data.frame(w[,c(5,11,13:22,24)])
```

```{r}
w2<- scale(w1)
summary(w2)

```

```{r}
numComplete <- NbClust(w2, distance="euclidean", min.nc=2, max.nc=10,
                       method="complete", index="all")

```

```{r}
names(numComplete)
```

```{r}
numComplete$Best.nc
```

```{r}
dis = dist(w2, method="euclidean")
```

```{r}
hc = hclust(dis, method="complete")
plot(hc, hang=-1,labels=FALSE, main="Complete-Linkage")
```

```{r}
comp4 <- cutree(hc, 4)
```

```{r}
library(NbClust) 
NbClust(w2, distance="euclidean", min.nc=2, max.nc=10,
        method="ward.D2", index="all")

```

```{r}
hcWard <- hclust(dis, method="ward.D2")

plot(hcWard, labels=FALSE, main="Ward's-Linkage")

ward3 <- cutree(hcWard, 3)

table(ward3)
```

```{r}
table(comp4, ward3)
```

```{r}
aggregate(w2,list(comp4),mean)

par(mfrow=c(1,2))
w3<- w2

```

```{r}
w4<-as.data.frame(cbind(w1, comp4, ward3))

table(w4$comp4,w4$ward3)

```

```{r}
dis = dist(w2, method="euclidean")
hc = hclust(dis, method="complete")

```

```{r}
res.coph <- cophenetic(hc)
```

```{r}
cor(dis, res.coph)
```

```{r}
NbClust(w2, min.nc=2, max.nc=15, method="kmeans")
```

```{r}
set.seed(1234)
km<- kmeans(w2,2,nstart=25)

```

```{r}
table(km$cluster)
```

```{r}
w3<-as.data.frame(cbind(w1, km$cluster))
colnames(w3)[14]<-"clusters"

```

```{r}
aggregate(w3[1:13], by=list(w3$clusters), FUN=mean)
```

```{r}
library(factoextra)
set.seed(1234)
km.res <- eclust(w2, "kmeans", k = 2, nstart = 25, graph = FALSE)

table(km.res$cluster)
fviz_cluster(km.res, geom = "point", ellipse.type = "norm",
             palette = "jco", ggtheme = theme_minimal())

```

```{r}
library(clValid)
```

```{r}
clmethods <- c("hierarchical","kmeans","pam")
intern <- clValid(w2, nClust = 2:4,
                  clMethods = clmethods, validation = "internal" )
```

```{r}
summary(intern)
```

SECTION 1 END HERE!
